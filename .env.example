# =============================================================================
# FreeRoute RAG Infra - 環境變數配置範例
# =============================================================================
#
# 使用說明：
# 1. 複製此檔案為 .env：cp .env.example .env
# 2. 根據您的需求修改變數值（特別是標記 ⚠️ 的必填項目）
# 3. 確保 .env 檔案在 .gitignore 中（已包含）
# 4. 執行：docker compose up -d --build
#
# 優先級：環境變數 > .env 檔案 > 預設值
# =============================================================================

# -----------------------------------------------------------------------------
# 🔧 基礎配置
# -----------------------------------------------------------------------------

# 時區設定（影響所有容器的時間顯示和日誌）
# 常用選項：Asia/Taipei, Asia/Shanghai, America/New_York, Europe/London
TZ=Asia/Taipei

# 平台架構（Apple M1/M2/M3 使用 linux/arm64，其他使用 linux/amd64）
# 不設定時自動選擇 linux/amd64
# PLATFORM=linux/amd64

# 應用版本號（用於追蹤和日誌）
APP_VERSION=v0.2.1

# 日誌級別（DEBUG, INFO, WARNING, ERROR, CRITICAL）
# 開發環境建議 DEBUG，生產環境建議 WARNING
LOG_LEVEL=INFO

# -----------------------------------------------------------------------------
# ⚠️ 必填：資料庫密碼
# -----------------------------------------------------------------------------

# PostgreSQL 資料庫密碼（LiteLLM 後端儲存）
# ⚠️ 必填：建議使用強密碼，至少 16 個字符
# 生產環境請務必更改！
POSTGRES_PASSWORD=change-me-to-secure-password

# Neo4j 資料庫密碼（知識圖譜儲存）
# ⚠️ 必填：生產環境請務必更改！
# 預設：neo4j123
NEO4J_PASSWORD=neo4j123

# -----------------------------------------------------------------------------
# ⚠️ 必填：LLM 供應商 API Keys
# -----------------------------------------------------------------------------

# OpenAI API Key
# ⚠️ 必填：主要的 LLM 推理服務（gpt-4o-mini, o1-mini 等）
# 獲取：https://platform.openai.com/api-keys
# 範例：sk-proj-...
OPENAI_API_KEY=

# Google Gemini API Key
# ⚠️ 必填：備用推理和 fallback（gemini-1.5-flash-8b）
# 獲取：https://aistudio.google.com/app/apikey
# 範例：AIza...
GOOGLE_API_KEY=

# OpenRouter API Key（選填，提供更多模型選擇）
# 獲取：https://openrouter.ai/keys
# 範例：sk-or-v1-...
OPENROUTER_API_KEY=

# Groq API Key（選填，快速推理：llama, mixtral 等）
# 獲取：https://console.groq.com/keys
# 範例：gsk_...
GROQ_API_KEY=

# -----------------------------------------------------------------------------
# 🔑 LiteLLM Proxy 配置
# -----------------------------------------------------------------------------

# LiteLLM Master Key（用於管理和訪問 LiteLLM Proxy）
# 預設：sk-admin
# ⚠️ 生產環境請務必更改！
LITELLM_MASTER_KEY=sk-admin

# LiteLLM UI 管理介面帳號密碼
# 訪問地址：http://localhost:9400
# ⚠️ 生產環境請務必更改！
UI_USERNAME=admin
UI_PASSWORD=admin123

# LiteLLM 連接配置（供 Gateway 內部使用）
LITELLM_BASE=http://litellm:4000/v1
LITELLM_KEY=sk-admin

# 是否將模型配置儲存在資料庫（建議保持 True）
STORE_MODEL_IN_DB=True

# 是否啟用 Prometheus 指標（true/false）
ENABLE_METRICS=True

# -----------------------------------------------------------------------------
# 💰 Token 用量控制（TokenCap 插件）
# -----------------------------------------------------------------------------

# OpenAI 每日 Token 用量上限（Tokens Per Day）
# 預設：9,000,000（保留 1M 供系統使用，實際可用 9M）
# 測試時可降低至 5000 來測試 fallback 機制
OPENAI_TPD_LIMIT=9000000

# 時區偏移（小時，用於計算每日重置時間）
# 台北/上海：8，紐約：-5（冬令）/-4（夏令），倫敦：0/1
TZ_OFFSET_HOURS=8

# 是否真正執行 reroute 到備用供應商（true/false）
# false 時會在達到上限後直接拒絕請求（測試用）
# true 時會自動切換到 Gemini 等免費供應商
OPENAI_REROUTE_REAL=true

# -----------------------------------------------------------------------------
# 🌐 API Gateway 配置
# -----------------------------------------------------------------------------

# Gateway API Key（用於外部訪問 Gateway 的認證）
# 預設：dev-key
# ⚠️ 生產環境請務必更改！可以設定多個，逗號分隔
# 範例：prod-key-123,backup-key-456
API_GATEWAY_KEYS=dev-key
GATEWAY_API_KEY=dev-key

# Gateway 連接其他服務的配置
QDRANT_URL=http://qdrant:6333
NEO4J_URI=bolt://neo4j:7687
NEO4J_USER=neo4j
RERANKER_URL=http://reranker:8080
OLLAMA_BASE=http://ollama:11434

# -----------------------------------------------------------------------------
# 🗺️ 知識圖譜抽取配置
# -----------------------------------------------------------------------------

# 知識圖譜 Schema 檔案路徑（容器內路徑）
GRAPH_SCHEMA_PATH=/app/schemas/graph_schema.json

# 圖譜抽取質量控制
# 最小節點數（低於此數量視為抽取失敗，需要重試）
GRAPH_MIN_NODES=1
# 最小邊數（低於此數量視為抽取失敗）
GRAPH_MIN_EDGES=1
# 是否允許空圖譜（true 時即使沒有抽取到也算成功）
GRAPH_ALLOW_EMPTY=false
# 最大重試次數（抽取失敗時的重試次數）
GRAPH_MAX_ATTEMPTS=2

# 供應商鏈（抽取失敗時依序嘗試的模型清單，逗號分隔）
# 順序：OpenAI GPT-4o-mini → O1-mini → Gemini
GRAPH_PROVIDER_CHAIN=graph-extractor,graph-extractor-o1mini,graph-extractor-gemini

# -----------------------------------------------------------------------------
# 📄 Ingestor 文件處理配置
# -----------------------------------------------------------------------------

# Gateway 連接配置（Ingestor 內部使用）
GATEWAY_BASE=http://apigw:8000

# 文件切分參數
# Chunk 大小（字符數，建議 500-2000）
CHUNK_SIZE=1000
# Chunk 重疊（字符數，建議 chunk_size 的 10-20%）
CHUNK_OVERLAP=200

# -----------------------------------------------------------------------------
# 🔗 Redis 配置
# -----------------------------------------------------------------------------

# Redis 連接 URL（用於 token 統計和快取）
REDIS_URL=redis://redis:6379/0
REDIS_HOST=redis
REDIS_PORT=6379

# -----------------------------------------------------------------------------
# 💾 PostgreSQL 配置（進階設定）
# -----------------------------------------------------------------------------

# 資料庫名稱（一般不需修改）
POSTGRES_DB=litellm
# 資料庫使用者（一般不需修改）
POSTGRES_USER=llmproxy

# -----------------------------------------------------------------------------
# 🎮 GPU 配置（有 NVIDIA GPU 時才需要）
# -----------------------------------------------------------------------------

# NVIDIA GPU 配置
# 如果沒有 GPU，可以註解掉或保持不變（Docker 會自動略過）
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=compute,utility

# -----------------------------------------------------------------------------
# 🤖 模型配置
# -----------------------------------------------------------------------------

# Reranker 模型配置
# 模型 ID（HuggingFace 模型路徑）
MODEL_ID=BAAI/bge-reranker-v2-m3
# 執行設備（auto 自動選擇 GPU/CPU，cpu 強制使用 CPU）
DEVICE=auto
# 資料類型（bfloat16, float16, float32）
# bfloat16 需要較新的 GPU（Ampere 或更新）
DTYPE=bfloat16
# Token 最大長度
TOKEN_MAXLEN=512

# HuggingFace 快取配置
TRANSFORMERS_CACHE=/models
HUGGINGFACE_HUB_CACHE=/models
HF_HUB_DISABLE_TELEMETRY=1

# Ollama 配置
# 模型保持載入的時間（避免重複載入）
OLLAMA_KEEP_ALIVE=24h

# -----------------------------------------------------------------------------
# 🔢 服務埠號對應（外部:內部）
# -----------------------------------------------------------------------------

# Qdrant 向量資料庫：         http://localhost:9333
# Neo4j HTTP 介面：           http://localhost:9474
# Neo4j Bolt 連接：           bolt://localhost:9687
# Redis：                     localhost:9379
# LiteLLM Proxy + UI：        http://localhost:9400
# Ollama：                    http://localhost:9143
# Reranker：                  http://localhost:9080
# API Gateway：               http://localhost:9800
# Ingestor：                  http://localhost:9900

# -----------------------------------------------------------------------------
# 📋 快速配置檢查清單
# -----------------------------------------------------------------------------

# ✅ 最小配置（必填項目）：
# 1. ⚠️ POSTGRES_PASSWORD     - PostgreSQL 密碼
# 2. ⚠️ NEO4J_PASSWORD         - Neo4j 密碼
# 3. ⚠️ OPENAI_API_KEY         - OpenAI API Key
# 4. ⚠️ GOOGLE_API_KEY         - Google Gemini API Key（fallback 用）

# 🔒 生產環境額外必做：
# 1. 更改所有預設密碼（POSTGRES_PASSWORD, NEO4J_PASSWORD）
# 2. 更改 LITELLM_MASTER_KEY 為強密碼
# 3. 更改 GATEWAY_API_KEY 為強密碼
# 4. 更改 UI_USERNAME 和 UI_PASSWORD
# 5. 設定適當的 LOG_LEVEL（建議 WARNING 或 ERROR）
# 6. 調整 OPENAI_TPD_LIMIT 根據您的用量需求
# 7. 關閉不需要的外部埠號（修改 docker-compose.yml）

# 🧪 測試環境建議：
# 1. LOG_LEVEL=DEBUG（方便除錯）
# 2. OPENAI_TPD_LIMIT=5000（測試 token cap 和 fallback 功能）
# 3. OPENAI_REROUTE_REAL=false（測試時不真正 reroute）
# 4. 保持預設密碼（但不要暴露在公網）

# -----------------------------------------------------------------------------
# ❓ 常見問題
# -----------------------------------------------------------------------------

# Q: 如何檢查配置是否正確？
# A: docker compose config

# Q: 如何重新載入環境變數？
# A: docker compose down && docker compose up -d --build

# Q: 如何查看服務日誌？
# A: docker compose logs -f <service_name>
#    範例：docker compose logs -f apigw

# Q: 哪些 API Keys 是必須的？
# A: OPENAI_API_KEY（主要）和 GOOGLE_API_KEY（fallback）

# Q: 可以不使用 GPU 嗎？
# A: 可以，將 DEVICE=cpu，但 Reranker 性能會下降

# Q: 如何測試 Token Cap 功能？
# A: 設定 OPENAI_TPD_LIMIT=5000 並發送多個請求

# Q: 忘記密碼怎麼辦？
# A: 修改 .env 中的密碼，然後執行：
#    docker compose down -v  # ⚠️ 會刪除所有資料！
#    docker compose up -d --build

# -----------------------------------------------------------------------------
# 📚 相關文檔
# -----------------------------------------------------------------------------

# 完整文檔：README.md, README.zh-TW.md
# API 使用：docs/zh/api_usage.md, docs/en/api_usage.md
# 架構設計：docs/architecture.md
# 故障排查：docs/troubleshooting.md
# 貢獻指南：CONTRIBUTING.md
# 產品路線圖：ROADMAP.md

# EOF
